# E-Musical: Art & Machine Learning Project 3 (Spring 2022)

This is the repo for E-Musical: a process for music generation using emotions from videos (through text and image analysis). 

Image-to-emotion generation uses EMONET, with code adapted from Github repository for the paper _"Estimation of continuous valence and arousal levels from faces in naturalistic conditions"_, by authors Antoine Toisoul, Jean Kossaifi, Adrian Bulat, Georgios Tzimiropoulos and Maja Pantic, published in Nature Machine Intelligence, January 2021 [[1]](#Citation).
Work done in collaboration between Samsung AI Center Cambridge and Imperial College London.



[[1]] "Estimation of continuous valence and arousal levels from faces in naturalistic conditions", Antoine Toisoul, Jean Kossaifi, Adrian Bulat, Georgios Tzimiropoulos and Maja Pantic, published in Nature Machine Intelligence, January 2021
